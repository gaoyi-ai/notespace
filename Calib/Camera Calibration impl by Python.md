---
title: Camera Calibration impl by Python
categories:
- 3D
- Camera Calibration
tags:
- Camera Calibration
date: 2022/6/7
---



# Camera Calibration

## Camera Geometry and The Pinhole Model

> [Camera Calibration. Camera Geometry and The Pinhole Model | by Aerin Kim | Towards Data Science](https://towardsdatascience.com/camera-calibration-fda5beb373c3)

Camera calibration or camera resectioning **estimates the parameters of a pinhole camera model** given photograph. Usually, the pinhole camera parameters are represented in a 3 Ã— 4 matrix called the camera matrix. We use these parameters to **estimate the actual size of an object** or **determine the location of the camera in the world**.

## How

Before we talk about camera calibration, first you need to understand how the pinhole camera works.

> Why do I need to know about the pinhole camera?

Because it is the essence of how any camera works. The pinhole camera model explains the relationship between a point in the world and the projection on the image plane (image sensor).

# The Pinhole Model

> How do we project the points in the world into a camera sensor?

å¦‚æœæˆ‘ä»¬ä½¿ç”¨å¹¿è§’ç›¸æœºçš„ä¼ æ„Ÿå™¨ï¼Œæˆ‘ä»¬æœ€ç»ˆä¼šå¾—åˆ°æ¨¡ç³Šçš„å›¾åƒï¼Œå› ä¸ºæˆåƒä¼ æ„Ÿå™¨åœ¨ä¼ æ„Ÿå™¨çš„åŒä¸€ä½ç½®æ”¶é›†æ¥è‡ªç‰©ä½“ä¸Šå¤šä¸ªç‚¹çš„å…‰çº¿ã€‚

è§£å†³è¿™ä¸ªé—®é¢˜çš„åŠæ³•æ˜¯åœ¨æˆåƒä¼ æ„Ÿå™¨å‰é¢æ”¾ä¸€ä¸ªå¸¦æœ‰å°å­”çš„å±éšœã€‚

å±éšœåªå…è®¸æœ‰é™çš„å…‰çº¿é€šè¿‡å­”ï¼Œå¹¶å‡å°‘å›¾åƒçš„æ¨¡ç³Šæ€§ã€‚

![img](https://miro.medium.com/max/875/1*z0V2rtG2WkLwKgPqu-QCpQ.jpeg)

https://en.wikipedia.org/wiki/Depth_of_field

[Example] ä¸åŒå…‰åœˆå¤§å°çš„çœŸå®å›¾åƒ

![img](https://miro.medium.com/max/875/1*ARDk0TScH0nSnbU-diaWsA.png)

https://en.wikipedia.org/wiki/Depth_of_field#Effect_of_lens_aperture

**The two most important parameters in a pinhole camera model**

1. **Focal length**: the distance between the pinhole and the image plane
    It affects **the size of the projected image**. It affects the camera **focus** when using lenses.

2. **Camera center:** The coordinates of the center of the **pinhole**.

![img](https://miro.medium.com/max/875/1*x2C8ksonO1JzBPqHfGzopQ.jpeg)

[https://en.wikipedia.org/wiki/Pinhole_camera_model](https://en.wikipedia.org/wiki/Pinhole_camera_model#geometry)

é’ˆå­”ç›¸æœºæ¨¡å‹éå¸¸ç®€å•ã€‚é€šè¿‡äº†è§£ç„¦è·å’Œç›¸æœºçš„ä¸­å¿ƒï¼Œæˆ‘ä»¬å¯ä»¥ç”¨æ•°å­¦æ–¹æ³•è®¡ç®—å‡ºä»ç‰©ä½“åå°„çš„å…‰çº¿å°†å°„å…¥å›¾åƒå¹³é¢çš„ä½ç½®ã€‚

The focal length and the camera center are the camera **intrinsic parameters, K**. (**K** is an industry norm to express the intrinsic matrix.)

# Coordinate System Transformation (via Matrix Algebra!)

![image-20220607185834978](images/Camera%20Calibration/image-20220607185834978.png)

> Why do we want this?
>
> **In order to project the point in the world frame to the camera image plane!**

**å…‰ï¼ˆä»ç‰©ä½“ä¸Šåå°„å‡ºæ¥çš„ï¼‰**ä»ä¸–ç•Œä¸Šé€šè¿‡ç›¸æœºå­”å¾„ï¼ˆé’ˆå­”ï¼‰åˆ°è¾¾ä¼ æ„Ÿå™¨è¡¨é¢ã€‚é€šè¿‡å…‰åœˆæŠ•å°„åˆ°ä¼ æ„Ÿå™¨è¡¨é¢çš„ç»“æœæ˜¯ç¿»è½¬çš„å›¾åƒã€‚ä¸ºäº†é¿å…ç¿»è½¬çš„æ··ä¹±ï¼Œæˆ‘ä»¬åœ¨ç›¸æœºä¸­å¿ƒçš„å‰é¢å®šä¹‰äº†ä¸€ä¸ªçš„**è™šæ‹Ÿå›¾åƒå¹³é¢**ï¼ˆé»„è‰²å¹³é¢ï¼‰ã€‚

![img](images/Camera%20Calibration/0fXQlnjpSwslSWVFC.png)

Diagram from [Simplified Camera Model Projection](https://www.researchgate.net/figure/Pinhole-Camera-Model-ideal-projection-of-a-3D-object-on-a-2D-image_fig1_326518096)

```
# World Coordinate System 
Oworld = [Xw, Yw, Zw]
# Camera Coordinate System
Ocamera = [Xc, Yc, Zc]
# Pixel Coordinate System
Oimage = [u,v]
```

We define a 3 by 3 **rotation matrix** (**R**) and a 3 by 1 **translation vector** (**t**) in order to model ANY transformation between a world coordinate system and another.

Now we can frame the projection problem (World Coordinates â†’ Image Coordinates) as

1. **World coordinates** â†’ Camera coordinates
2. Camera coordinates â†’ **Image coordinate**

```
Oworld [Xw,Yw,Zw] â†’ Oimage [u,v]
```

## How? by using Linear Algebra!

```
1. World coordinates â†’  Camera coordinates
Ocamera = [R|t] * Oworld
2. Camera coordinates â†’ Image coordinate
Oimage = K * Ocamera 
Remind me what K (camera intrinsic parameter) was?
```

![img](https://miro.medium.com/max/205/1*COt2h9WgoWzpv035yPaUCA.png)

**intrinsic parameters, K: f for focal length, c for camera center, which are camera specific params**

Both steps 1 and 2 are just matrix multiplications. Therefore it can be re-written (combined) as:

```
Oimage = P * Oworld = K[R|t] * Oworld
Let P = K[R|t]
P as Projection
```

Wait, **K** is (3,3) matrix. **[R|t]** is (3,4). (| means you are concatenating matrix **R** with vector **t**.) **Oworld [Xw,Yw,Zw]** is (3,1).

Then you canâ€™t multiply **K[R|t] (3,4)** with **Oworld [Xw,Yw,Zw] (3,1)**!

ğŸ˜ We can resolve this by adding one at the end the Oworld vector **[Xw,Yw,Zw,1], called homogeneous coordinate (or projective coordinate)**.

If you want to further transform image coordinates to pixel coordinates: Divide x and y by z to get homogeneous coordinates in the image plane.

```
[x, y, z] -> [u, v, 1] = 1/z * [x, y, z]
```

This is it. This is the core. **This simple projection principle will be used in every 3d visual perception algorithm, from object detection to 3d scene reconstruction.**

åœ¨ç°å®ç”Ÿæ´»ä¸­ï¼Œä¼šæœ‰æ›´å¤æ‚çš„æƒ…å†µï¼Œä¾‹å¦‚ï¼Œéæ­£æ–¹å½¢çš„åƒç´ ã€ç›¸æœºæ¥å…¥çš„å€¾æ–œã€å¤±çœŸã€éå•ä½é•¿å®½æ¯”ç­‰ã€‚ç„¶è€Œï¼Œ**ä»–ä»¬åªæ”¹å˜äº†æ‘„åƒæœºçŸ©é˜µK**ï¼Œæ–¹ç¨‹ä»ç„¶æ˜¯ä¸€æ ·çš„ã€‚

A few things to note:

...

c) å›¾åƒåæ ‡ï¼ˆè™šæ‹Ÿå›¾åƒå¹³é¢ï¼‰[u, v]ä»è™šæ‹Ÿå›¾åƒå¹³é¢çš„å·¦ä¸Šè§’å¼€å§‹ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬è¦å°†åƒç´ ä½ç½®è°ƒæ•´åˆ°å›¾åƒåæ ‡å¸§ã€‚

# Seeing is believing

Take a look at the function `project_ego_to_image`. It calls two functions in a row, `project_ego_to_cam` first, then`project_cam_to_image` , just as we converted the world coordinate into the image coordinate by breaking it down into 2 steps: **World coordinates** â†’ Camera coordinates, then Camera coordinates â†’ **Image coordinate**.

`cart2hom` converts Cartesian coordinates into Homogeneous coordinates.

<script src="https://gist.github.com/aerinkim/d00e07b8aee06a8d83cba4a6c022527f.js"></script>

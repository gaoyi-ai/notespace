---
title: Decision Tree
categories:
- ML
tags:
- prune
date: 2021/1/13 20:00:12
updated: 2021/1/13 21:00:12
---

# 决策树

## 剪枝

在不加限制的状况下，一颗决策树会生长到衡量不纯度的指标最优或者没有更多的特征可用为止。
那这样的决策树呢往往会过拟合，就是说它会在训练集上表现的很好。但是在测试集上却表现的非常糟糕。收集到的样本数据呢，本质是对不可得的整体数据的一个抽样。所以它和整体的状况不会完全一致。因此当一棵决策树它这个模型，对训练数据有了过于优秀的解释性。

那它找出的规则必然是包含了训练样本中的噪声的规则的，这会使它对未知数据的拟合程度不足，就会使它在测试集上表现糟糕，偏离整体可能本来存在的样子。

## 交叉验证

我们之前在做这个分类树的时候，我们提到说每个人分出来的结果应该是不一样的。除了这个分类树本身的这种随机性之外。还有一个东西不一样，就是这个测试集和训练集的划分。`train_test_split` 这么一个类它的划分，因为不同的测试集和训练集。它会影响我们模型的结果。我们的模型是用训练集训练出来的。所以每个人的模型都不一样。

那我怎么知道说我训练出来的这个模型。到其他的这个训练集，或者到这个不可获得的整体的数据集的其他的数据，还会有这种相似的效果。我怎么知道我的模型的泛化性到底有多强呢？怎么来解决这个问题呢？

还记得我们在分类树中讲的是想选一棵最优的时候，怎么办？我们会种很多棵，然后选一棵最好的，
那这个划分训练集和测试集也是一样的，我们可以多次来做，然后求一个平均来看看，我们的模型到底有多么稳定。

==交叉验证==是用来观察模型的稳定性的一种方法，我们将数据划分为n份，依次使用其中一份作为测试集，其他n-1份作为训练集，多次计算模型的精确性来评估模型的平均准确程度。训练集和测试集的划分会干扰模型的结果，因此用交叉验证n次的结果求出的平均值，是对模型效果的一个更好的度量。

## 目标权重

什么叫做样本标签不平衡呢？

它是说在一组数据当中，标签的一类天生占有很大的比例。比如说在银行要判断一个办了信用卡的人是否会违约，这个问题里面会违约的人其实是非常少的。大部分的人他是不会违约的吧，就是说会违约的人对上不会违约的人，这个比例可能是1%比99%。不会违约的人是大多数，但是银行真正在意的其实是那些会违约的人。我想知道哪些人会违约，然后我好给他拒之门外吧，我就不给他发信用卡。对不对？我都知道我要亏，我为什么要给他发信用卡呢？在这种状况下呢，决策树会天生地像占比例很大的那一类标签去偏移，它会偏过去，这会导致可能对那些我们的目标，那些会违约的人的捕捉度非常非常的低。
这种分类状况下，即使模型什么都不做，把所有的结果都预测成不会违约，正确率也能有 .99，那score 也能有 .99 以上，对不对？但是有用吗？没有用。
---
title: Maximum Likelihood Estimation
categories:
- Math
- Statistic
tags:
- MLE
- MAP
date: 2021/3/3 10:00:00
updated: 2021/3/4 12:00:00
---

# 极大似然估计

极大似然估计，通俗理解来说，**就是利用已知的样本结果信息，反推最具有可能（最大概率）导致这些样本结果出现的模型参数值**。**换句话说，极大似然估计提供了一种给定观察数据来评估模型参数的方法，即：“模型已定，参数未知”。**

这样想，一旦模型满足某个分布，它的参数值通过极大似然估计法求出来的话。比如正态分布中公式如下：
$$
f(x)=\frac{1}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)
$$
如果通过极大似然估计，得到模型中参数$\mu$和$\sigma$的值，那么这个模型的均值和方差以及其它所有的信息是不是就知道了呢。确实是这样的。

**极大似然估计中采样需满足一个重要的假设，就是所有的采样都是独立同分布的。**

下面通过2个例子来帮助理解一下最大似然估计。

但是首先看一下似然函数 $p(x|\theta)$ 的理解：

对于这个函数： $p(x|\theta)$ 输入有两个：x表示某一个具体的数据； $\theta$ 表示模型的参数

如果 $\theta$ 是已知确定的， x 是变量，这个函数叫做概率函数(probability function)，它描述对于不同的样本点 x ，其出现概率是多少。

如果 x 是已知确定的， $\theta$ 是变量，这个函数叫做似然函数(likelihood function), 它描述对于不同的模型参数，出现 x 这个样本点的概率是多少。

其实这样的形式我们以前也不是没遇到过。例如， $f(x,y)=x^y$ , 即x的y次方。如果x是已知确定的(例如x=2)，这就是 $f(y)=2^y$ , 这是指数函数。 如果y是已知确定的(例如y=2)，这就是 $f(x)=x^2$ ，这是二次函数。同一个数学形式，从不同的变量角度观察，可以有不同的名字。

**例子一**

假如有一个罐子，里面有黑白两种颜色的球，数目多少不知，两种颜色的比例也不知。我们想知道罐中白球和黑球的比例，但我们不能把罐中的球全部拿出来数。现在我们可以每次任意从已经摇匀的罐中拿一个球出来，记录球的颜色，然后把拿出来的球 再放回罐中。这个过程可以重复，我们可以用记录的球的颜色来估计罐中黑白球的比例。假如在前面的一百次重复记录中，有七十次是白球，请问罐中白球所占的比例最有可能是多少？

**很多人马上就有答案了：70%。而其后的理论支撑是什么呢？**

我们假设罐中白球的比例是p，那么黑球的比例就是1-p。因为每抽一个球出来，在记录颜色之后，我们把抽出的球放回了罐中并摇匀，**所以每次抽出来的球的颜色服从同一独立分布。**

这里我们把一次抽出来球的颜色称为一次抽样。题目中在一百次抽样中，七十次是白球的,三十次为黑球事件的概率是P(样本结果|Model)。

如果第一次抽象的结果记为x1,第二次抽样的结果记为x2....那么样本结果为(x1,x2.....,x100)。这样，我们可以得到如下表达式：

P(样本结果|Model)

　　= P(x1,x2,…,x100|Model)

　　= P(x1|M)P(x2|M)…P(x100|M)

　　= p^70(1-p)^30.

我们已经有了观察样本结果出现的概率表达式了。那么我们要求的模型的参数，也就是求的式中的p。

那么我们怎么来求这个p呢？

不同的p，直接导致P（样本结果|Model）的不同。

好的，我们的p实际上是有无数多种分布的。如下：

| p (白球比例) | 1-p (黑球比例) |
| ------------ | -------------- |
| 0.5          | 0.5            |

那么求出 p^70(1-p)^30为 7.8 * 10^(-31)

p的分布也可以是如下：

| p (白球比例) | 1-p (黑球比例) |
| ------------ | -------------- |
| 0.7          | 0.3            |

那么也可以求出p^70(1-p)^30 为 2.95* 10^(-27)

**那么问题来了，既然有无数种分布可以选择，极大似然估计应该按照什么原则去选取这个分布呢？**

**答：采取的方法是让这个样本结果出现的可能性最大，也就是使得p^70(1-p)^30值最大，那么我们就可以看成是p的方程，求导即可**

那么既然事情已经发生了，为什么不让这个出现的结果的可能性最大呢？**这也就是最大似然估计的核心。**

我们想办法让观察样本出现的概率最大，转换为数学问题就是使得：p^70(1-p)^30最大，未知数只有一个p，我们令其导数为0，即可求出p为70%，与我们一开始认为的70%是一致的。其中蕴含着我们的数学思想在里面。

**例子二**

假设我们要统计全国人民的年均收入，首先假设这个收入服从服从正态分布，但是该分布的均值与方差未知。我们没有人力与物力去统计全国每个人的收入。我们国家有10几亿人口呢？那么岂不是没有办法了？

有了极大似然估计之后，比如选取一个城市，或者一个乡镇的人口收入，作为观察样本结果。然后通过最大似然估计来获取上述假设中的正态分布的参数。

有了参数的结果后，就可以知道该正态分布的期望和方差了。也就是通过了一个小样本的采样，反过来知道了全国人民年收入的一系列重要的数学指标量

那么我们就知道了极大似然估计的核心关键就是对于一些情况，样本太多，无法得出分布的参数值，可以采样小样本后，利用极大似然估计获取假设中分布的参数值。

# MLE

最大似然估计（Maximum likelihood estimation, 简称 MLE）和最大后验概率估计（Maximum a posteriori estimation, 简称 MAP）是很常用的两种参数估计方法，如果不理解这两种方法的思路，很容易弄混它们。下文将详细说明 MLE 和 MAP 的思路与区别。

但别急，我们先从概率和统计的区别讲起。

## 概率和统计是一个东西吗？

概率（probabilty）和统计（statistics）看似两个相近的概念，其实研究的问题刚好相反。

概率研究的问题是，已知一个模型和参数，怎么去预测这个模型产生的结果的特性（例如均值，方差，协方差等等）。 举个例子，我想研究怎么养猪（模型是猪），我选好了想养的品种、喂养方式、猪棚的设计等等（选择参数），我想知道我养出来的猪大概能有多肥，肉质怎么样（预测结果）。

统计研究的问题则相反。统计是，有一堆数据，要利用这堆数据去预测模型和参数。仍以猪为例。现在我买到了一堆肉，通过观察和判断，我确定这是猪肉（这就确定了模型。在实际研究中，也是通过观察数据推测模型是／像高斯分布的、指数分布的、拉普拉斯分布的等等），然后，可以进一步研究，判定这猪的品种、这是圈养猪还是跑山猪还是网易猪，等等（推测模型参数）。

一句话总结：**概率是已知模型和参数，推数据。统计是已知数据，推模型和参数。**

显然，本文解释的 MLE 和 MAP 都是统计领域的问题。它们都是用来推测参数的方法。为什么会存在着两种不同方法呢？ 这需要理解贝叶斯思想。我们来看看贝叶斯公式。

## 贝叶斯公式到底在说什么？

学习机器学习和模式识别的人一定都听过贝叶斯公式 (Bayes’ Theorem)：
$$
P(A \mid B)=\frac{P(B \mid A) P(A)}{P(B)}
$$
贝叶斯公式看起来很简单，无非是倒了倒条件概率和联合概率的公式。

把 B 展开，可以写成：
$$
P(A \mid B)=\frac{P(B \mid A) P(A)}{P(B \mid A) P(A)+P(B \mid \sim A) P(\sim A)}
$$
这个式子就很有意思了。

想想这个情况。一辆汽车（或者电瓶车）的警报响了，你通常是什么反应？有小偷？撞车了？ 不。。 你通常什么反应都没有。因为汽车警报响一响实在是太正常了！每天都要发生好多次。本来，汽车警报设置的功能是，出现了异常情况，需要人关注。然而，由于虚警实在是太多，人们渐渐不相信警报的功能了。

**贝叶斯公式就是在描述，你有多大把握能相信一件证据？（how much you can trust the evidence）**

我们假设响警报的目的就是想说汽车被砸了。把 A 计作 “汽车被砸了”，B 计作 “警报响了”，带进贝叶斯公式里看。我们想求等式左边发生$A \mid B$的概率，这是在说警报响了，汽车也确实被砸了。汽车被砸 引起（trigger）警报响$(B \mid A)$。但是，也有可能是汽车被小孩子皮球踢了一下、被行人碰了一下等其他原因（统统计作$\sim A$）其他原因引起汽车警报响了，即$B \mid \sim A$。那么，现在突然听见警报响了，这时汽车已经被砸了的概率是多少呢（这即是说，警报响这个_证据_有了，多大把握能相信它确实是在报警说汽车被砸了）？想一想，应当这样来计算。用警报响起、汽车也被砸了这事件的数量，除以响警报事件的数量（这即 式 1）。进一步展开，即警报响起、汽车也被砸了的事件的数量，除以警报响起、汽车被砸了的事件数量加上警报响起、汽车没被砸的事件数量（这即 式 2）。

可能有点绕，请稍稍想一想。

再思考 式 2。想让$P(A \mid B)=1$ ，即警报响了，汽车一定被砸了，该怎么做呢？让$ P(B|\sim A)P(\sim A) = 0$ 即可。很容易想清楚 ， 假若让 $P(\sim A)=0$即杜绝了汽车被球踢、被行人碰到等等其他所有情况，那自然，警报响了，只剩下一种可能——汽车被砸了。这即是提高了响警报这个证据的说服力。

**从这个角度总结贝叶斯公式：做判断的时候，要考虑所有的因素。** 老板骂你，不一定是你把什么工作搞砸了，可能只是他今天出门前和太太吵了一架。

再思考 式 2。观察 式 2右边的分子，$P(B|A)$ 为汽车被砸后响警报的概率。姑且仍为这是 1 吧。但是，若$P(A)$ 很小，即汽车被砸的概率本身就很小，则 $P(B|A) P(A)$  仍然很小，即 式 2右边分子仍然很小，$P(A|B)$ 还是大不起来。 这里，$P(A)$ 即是常说的先验概率，如果 A 的先验概率很小，就算 $P(B|A)$较大，可能 A 的后验概率 $P(A|B)$ 还是不会大（假设$P(B∣∼A)P(∼A)$ 不变的情况下）。

**从这个角度思考贝叶斯公式：一个本来就难以发生的事情，就算出现某个证据和他强烈相关，也要谨慎。证据很可能来自别的虽然不是很相关，但发生概率较高的事情。** 发现刚才写的代码编译报错，可是我今天状态特别好，这语言我也很熟悉，犯错的概率很低。因此觉得是编译器出错了。 ————别，还是先再检查下自己的代码吧。

## 最大似然估计（MLE）

假设有一个造币厂生产某种硬币，现在我们拿到了一枚这种硬币，想试试这硬币是不是均匀的。即想知道抛这枚硬币，正反面出现的概率（记为$\theta$）各是多少？

这是一个统计问题，回想一下，解决统计问题需要什么？ 数据！

于是我们拿这枚硬币抛了 10 次，得到的数据（$x_0$​）是：反正正正正反正正正反。我们想求的正面概率$\theta$是模型参数，而抛硬币模型我们可以假设是 二项分布。

那么，出现实验结果 $ x_0$（即反正正正正反正正正反）的似然函数是多少呢？

$$
\begin{array}{l}
f\left(x_{0}, \theta\right)=(1-\theta) \times \theta \times \theta \times \theta \times \theta \times(1-\theta) \times \theta \times \theta \times \theta \times(1-\theta)=\theta^{7}(1-\theta)^{3}= f(\theta)
\end{array}
$$
注意，这是个只关于$\theta$的函数。而最大似然估计，顾名思义，就是要最大化这个函数。我们可以画出 $f(\theta)$的图像：

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/59cce91b31a30bcbff20516cf1806215.png" alt="likeli" style="zoom: 25%;" />

可以看出，在$\theta=0.7$时，似然函数取得最大值。

这样，我们已经完成了对$\theta $的最大似然估计。即，抛 10 次硬币，发现 7 次硬币正面向上，最大似然估计认为正面向上的概率是 0.7。（ummm… 这非常直观合理，对吧？）

且慢，一些人可能会说，硬币一般都是均匀的啊！ 就算你做实验发现结果是 “反正正正正反正正正反”，我也不信 $\theta = 0.7$。

这里就包含了贝叶斯学派的思想了——要考虑先验概率。 为此，引入了最大后验概率估计。

## 最大后验概率估计

最大似然估计是求参数 $\theta$, 使似然函数 $P(x_0 | \theta)$ 最大。最大后验概率估计则是想求 $\theta$ 使$P(x_0 | \theta) P(\theta)$ 最大 。 求得的 $\theta$ 不单单让似然函数大，$\theta$ 自己出现的先验概率也得大. （这有点像正则化里加惩罚项的思想，不过正则化里是利用加法，而 MAP 里是利用乘法）

MAP 其实是在最大化 $ P(\theta|x_0)=\frac{P(x_0|\theta)P(\theta)}{P(x_0)}$，不过因为 $x_0$是确定的（即投出的 “反正正正正反正正正反”）， $P(x_0)$ 是一个已知值，所以去掉了分母 $P(x_0)$（假设 “投 10 次硬币” 是一次实验，实验做了 1000 次，“反正正正正反正正正反”出现了 n 次，则 $P(x_0) = n/1000 $。总之，这是一个可以由数据集得到的值）。最大化 $P(\theta | x_0)$ 的意义也很明确， $x_0$已经出现了，要求$\theta$取什么值使 $P(\theta | x_0)$ 最大。顺带一提， $P(\theta | x_0)$ 即后验概率，这就是 “最大后验概率估计” 名字的由来。

对于投硬币的例子来看，我们认为（” 先验地知道 “）$\theta$取 0.5 的概率很大，取其他值的概率小一些。我们用一个高斯分布来具体描述我们掌握的这个先验知识，例如假设$P(\theta) $为均值 0.5，方差 0.1 的高斯函数，如下图：

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/63ac4f85c2439a7167012aeca9b20a26.png" alt="ptheta" style="zoom:25%;" />

则 $P(x_0 | \theta) P(\theta) $的函数图像为：

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/f8d0f3edd20990f27e43367b41d0c0f9.png" alt="map1" style="zoom:25%;" />

注意，此时函数取最大值时， $\theta $取值已向左偏移，不再是 0.7。实际上，在 $\theta=0.558$ 时函数取得了最大值。即，用最大后验概率估计，得到 $\theta=0.558$

最后，那要怎样才能说服一个贝叶斯派相信 $ \theta = 0.7 $呢？你得多做点实验。。

如果做了 1000 次实验，其中 700 次都是正面向上，这时似然函数为:

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/628f070547dd6c702e597a75d39ad743.png" alt="likeli2" style="zoom:25%;" />

如果仍然假设 $P(\theta)$ 为均值 0.5，方差 0.1 的高斯函数，$ P(x_0 | \theta) P(\theta)$的函数图像为：

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/7dba20cbd0a68da44a5253d889f27969.png" alt="map2" style="zoom:25%;" />

在$ \theta = 0.696 $ 处， $ P(x_0 | \theta) P(\theta) $取得最大值。

这样，就算一个考虑了先验概率的贝叶斯派，也不得不承认得把 $\theta $估计在 0.7 附近了。

PS. 要是遇上了顽固的贝叶斯派，认为 $ P(\theta = 0.5) = 1 $ ，那就没得玩了。。 无论怎么做实验，使用 MAP 估计出来都是$ \theta = 0.5 $。这也说明，一个合理的先验概率假设是很重要的。（通常，先验概率能从数据中直接分析得到）

## 最大似然估计和最大后验概率估计的区别

相信读完上文，MLE 和 MAP 的区别应该是很清楚的了。MAP 就是多个作为因子的先验概率$P(\theta)$。或者，也可以反过来，认为 MLE 是把先验概率$P \theta)$ 认为等于 1，即认为 $\theta$是均匀分布。

---

>在统计学中，**最大概率估计（MLE）**是一种通过[最大化](https://en.wikipedia.org/wiki/Mathematical_optimization)概率[函数](https://en.wikipedia.org/wiki/Likelihood_function)来[估计](https://en.wikipedia.org/wiki/Estimation_theory)[概率分布](https://en.wikipedia.org/wiki/Probability_distribution)[参数](https://en.wikipedia.org/wiki/Statistical_parameter)的方法，因此在假定的[统计模型](https://en.wikipedia.org/wiki/Statistical_model)下[，观测到的数据](https://en.wikipedia.org/wiki/Realization_(probability))最有可能。[参数空间](https://en.wikipedia.org/wiki/Parameter_space)中最大化可能性函数的[点](https://en.wikipedia.org/wiki/Point_estimate)称为最大可能性估计值。

## 什么是参数？

在机器学习中，我们经常使用一个模型来描述生成观察数据的过程。例如，我们可以使用一个随机森林模型来分类客户是否会取消订阅服务（称为流失建模），或者我们可以用线性模型根据公司的广告支出来预测公司的收入（这是一个线性回归的例子）。每个模型都包含自己的一组参数，这些参数最终定义了模型本身。

我们可以把线性模型写成 y = mx + c 的形式。在广告预测收入的例子中，x 可以表示广告支出，y 是产生的收入。m 和 c 则是这个模型的参数。这些参数的不同值将在坐标平面上给出不同的直线（见下图）。

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/91345image.png" style="zoom:33%;" />

_参数值不同的三个线性模型。_

因此，参数为模型定义了一个蓝图。只有将参数选定为特定值时，才会给出一个描述给定现象的模型实例。

## 最大似然估计的直观解释

最大似然估计是一种确定模型参数值的方法。确定参数值的过程，是找到能最大化模型产生真实观察数据可能性的那一组参数。

上述的定义可能听起来还是有点模糊，那么让我们通过一个例子来帮助理解。

假设我们从某个过程中观察了 10 个数据点。例如，每个数据点可以代表一个学生回答特定考试问题的时间长度（以秒为单位）。这 10 个数据点如下图所示：

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/83630image%20(1).png" style="zoom:33%;" />

_我们观察到的 10 个（假设的）数据点。_  

我们首先要决定哪个模型最适合描述生成数据的过程，这一步至关重要。至少，我们应该对使用哪种模型有一个不错的想法。这个判断通常来自于一些领域内专家，但我们不在这里讨论这个问题。

对于这些数据，我们假设数据生成过程可以用高斯分布（正态分布）进行充分描述。对以上数值目测一番就可以得知，高斯分布是合理的，因为这 10 个点的大部分都集中在中间，而左边和右边的点都很少。（因为我们只使用了 10 个数据点，做出这样的草率决定是不明智的，但考虑到我是用某个确定的分布函数生成这些数据点，我们就凑合着用吧）。

回想一下高斯分布有两个参数：均值μ和标准差σ。这些参数的不同值会对应不同的曲线（就像上面的直线一样）。我们想知道「哪条曲线最可能产生我们观察到的数据点」？（见下图）。用最大似然估计法，我们会找到与数据拟合得最好的 μ、σ 的值。

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/29450image%20(2).png" style="zoom:33%;" />

_10 个数据点和可能得出这些数据的高斯分布。f_1 是均值为 10、方差为 2.25（方差等于标准偏差的平方）的正态分布，也可以表示为 f_1∼N(10, 2.25)。其它曲线为 f_2∼N(10, 9)、f_3∼N(10, 0.25)、f_4∼N(8,2.25)。最大似然的目标是找到最有可能生成已知观察数据分布的参数值。_

我生成这 10 个数据的真实分布是 f_1~N(10, 2.25)，也就是上图中的蓝色曲线。

### 计算最大似然估计

现在我们对最大似然估计有了直观的理解，我们可以继续学习如何计算参数值了。我们找到的参数值被称为最大似然估计（maximum likelihood estimates，MLE）。

我们同样将用一个例子来演示这个过程。假设这次有三个数据点，我们假设它们是从一个被高斯分布充分描述的过程生成的。这些点是 9、9.5 和 11。那么如何用最大似然估计逼近这个高斯分布的参数 μ 和 σ 呢?

我们要计算的是同时观察到所有这些数据的概率，也就是所有观测数据点的联合概率分布。因此，我们需要计算一些可能很难算出来的条件概率。我们将在这里做出第一个假设，假设每个数据点都是独立于其他数据点生成的。这个假设能让计算更容易些。如果事件（即生成数据的过程）是独立的，那么观察所有数据的总概率就是单独观察到每个数据点的概率的乘积（即边缘概率的乘积）。

从高斯分布中生成的单个数据点 x 的（边缘）概率是：
$$
P(x ; \mu, \sigma)=\frac{1}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)
$$
  在表达式 P(x; μ, σ) 中的分号是为了强调在分号后的符号都是概率分布的参数。所以千万不要把这个与条件概率相混淆。条件概率一般会用竖线来表达，比如说 P(A| B)。

在我们的例子中，同时观察到这三个数据点的总（联合）概率是：
$$
\begin{aligned}
P(9,9.5,11 ; \mu, \sigma)=\frac{1}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{(9-\mu)^{2}}{2 \sigma^{2}}\right) \times \frac{1}{\sigma \sqrt{2 \pi}} \exp &\left(-\frac{(9.5-\mu)^{2}}{2 \sigma^{2}}\right)
\times \frac{1}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{(11-\mu)^{2}}{2 \sigma^{2}}\right)
\end{aligned}
$$
我们只要找出能够让上述表达式最大化的μ、σ值就可以了。

如果你在数学课上学过微积分，那么你可能会意识到有一种技巧可以帮助我们找到函数的最大值（和最小值）。我们所要做的就是求出函数的导数，把导函数设为零然后重新变换方程，使其参数成为方程的未知数。然后就这样，我们将得到参数的 MLE 值。我将串讲一下这些步骤，但我假设读者知道如何对常用函数进行微分。

#### 对数似然函数

上述的总概率表达式实际上是很难微分，所以它几乎总是通过对表达式取自然对数进行简化。这完全没问题，因为自然对数是一个单调递增的函数。这意味着，如果 x 轴上的值增加，y 轴上的值也会增加（见下图）。这一点很重要，因为它确保了概率的最大对数值出现在与原始概率函数相同的点上。因此，我们可以用更简单的对数概率来代替原来的概率。

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/60917image%20(6).png" style="zoom:33%;" />

_原函数的单调性，左边是 y = x，右边是（自然）对数函数 y = ln(x)。_

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/02159image%20(7).png" style="zoom:33%;" />

_这是一个非单调函数的例子，因为从左至右 f(x) 会上升，然后下降，然后又上升。_

取初始表达式的对数能得到：
$$
\begin{aligned}
\ln (P(x ; \mu, \sigma))=\ln \left(\frac{1}{\sigma \sqrt{2 \pi}}\right)-\frac{(9-\mu)^{2}}{2 \sigma^{2}}+\ln \left(\frac{1}{\sigma \sqrt{2 \pi}}\right)-& \frac{(9.5-\mu)^{2}}{2 \sigma^{2}} +\ln \left(\frac{1}{\sigma \sqrt{2 \pi}}\right)-\frac{(11-\mu)}{2 \sigma^{2}}
\end{aligned}
$$
  我们可以用对数的运算法则再一次简化这个表达式，得到：
$$
\ln (P(x ; \mu, \sigma))=-3 \ln (\sigma)-\frac{3}{2} \ln (2 \pi)-\frac{1}{2 \sigma^{2}}\left[(9-\mu)^{2}+(9.5-\mu)^{2}+(11-\mu)^{2}\right]
$$
  这个表达式可以通过求导得到最大值。在这个例子中，我们要找到平均值 μ。为此我们对函数求μ的偏导数，得到：
$$
\frac{\partial \ln (P(x ; \mu, \sigma))}{\partial \mu}=\frac{1}{\sigma^{2}}[9+9.5+11-3 \mu]
$$
  最后，设置等式的左边为零，然后以μ为未知数整理式子，可以得到：
$$
\mu=\frac{9+9.5+11}{3}=9.833
$$
这样我们就得到了 μ 的最大似然估计。我们可以用同样的方法得到σ的最大似然估计，这留给有兴趣的读者自己练习。

### 最大似然估计小结

#### 最大似然估计总是能精确地得到解吗？

简单来说，不能。更有可能的是，在真实的场景中，对数似然函数的导数仍然是难以解析的（也就是说，很难甚至不可能人工对函数求微分）。因此，一般采用期望最大化（EM）算法等迭代方法为参数估计找到数值解，但总体思路还是一样的。

#### 为什么叫「最大似然（最大可能性）」，而不是「最大概率」呢？

好吧，这只是统计学家们卖弄学问（但也是有充分的理由）。大多数人倾向于混用「概率」和「似然度」这两个名词，但统计学家和概率理论家都会区分这两个概念。通过观察这个等式，我们可以更好地明确这种混淆的原因。
$$
L(\mu, \sigma ; \text { data })=P(\text { data } ; \mu, \sigma)
$$
  这两个表达式是相等的！所以这是什么意思？我们先来定义 P(data; μ, σ) 它的意思是「在模型参数μ、σ条件下，观察到数据 data 的概率」。值得注意的是，我们可以将其推广到任意数量的参数和任何分布。

另一方面，L(μ, σ; data) 的意思是「我们在观察到一组数据 data 之后，参数μ、σ取特定的值的似然度。」

上面的公式表示，给定参数后数据的概率等于给定数据后参数的似然度。但是，尽管这两个值是相等的，但是似然度和概率从根本上是提出了两个不同的问题——一个是关于数据的，另一个是关于参数值的。这就是为什么这种方法被称为最大似然法（极大可能性），而不是最大概率。

#### 什么时候最小二乘参数估计和最大似然估计结果相同？

最小二乘法是另一种常用的机器学习模型参数估计方法。结果表明，当模型向上述例子中一样被假设为高斯分布时，MLE 的估计等价于最小二乘法。

直觉上，我们可以通过理解两种方法的目的来解释这两种方法之间的联系。对于最小二乘参数估计，我们想要找到最小化数据点和回归线之间距离平方之和的直线（见下图）。在最大似然估计中，我们想要最大化数据同时出现的总概率。当待求分布被假设为高斯分布时，最大概率会在数据点接近平均值时找到。由于高斯分布是对称的，这等价于最小化数据点与平均值之间的距离。

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/86568image%20(13).png" style="zoom:33%;" />

_有随机高斯噪声的回归线_

上一部分讨论了机器学习和统计模型中参数估计的最大似然法。在下文我们将讨论贝叶斯推理的参数估计，并解释该方法如何可作为最大似然法的推广，以及两者等价的条件。

阅读本文需要理解一些基本的概率论知识，例如边缘概率和条件概率。此外，了解高斯分布有助于理解，但并不是必要的。

### 贝叶斯定理

在介绍贝叶斯推理之前，理解贝叶斯定理是很有必要的。贝叶斯定理的意义在于使我们能利用已有的知识或信念（通常称为先验的）帮助计算相关事件的概率。例如，如果想知道在炎热和晴朗的天气中卖出冰淇淋的概率，贝叶斯定理可以使用「在其它类型天气中可能卖出冰淇淋数量」的先验知识。

#### 数学定义

贝叶斯定理的数学定义如下：
$$
P(A \mid B)=\frac{P(B \mid A) \times P(A)}{P(B)}
$$
其中，A 和 B 是事件，P(A|B) 是给定事件 B 发生时，事件 A 发生的条件概率，P(B|A) 同理。P(A) 和 P(B) 分别是事件 A 和事件 B 的边缘概率。

#### 示例

假定一副扑克牌里有 52 张牌，其中 26 张是红色的，26 张是黑色的。那么当牌是红色的时候，牌上数字为 4 的概率是多少？

我们将牌为数字 4 设为事件 A，将牌为红色设为事件 B。因此我们需要计算的概率是 P(A|B)=P(4|red)，接下来，我们使用贝叶斯定理计算这个概率值：

1. P(B|A) = P(red|4) = 1/2

2. P(A) = P(4) = 4/52 = 1/13

3. P(B) = P(red) = 1/2

然后根据贝叶斯定理可得到：P(4|red)=P(red|4)·P(4)/P(red)=1/13。

#### 为什么贝叶斯定理能结合先验信念？

仅仅看数学公式很难理解这一点。我们将再次借用冰淇淋和天气的例子。

令 A 为卖出冰淇淋的事件，B 为天气的事件。我们的问题是「给定天气的类型，卖出冰淇淋的概率是多少？」用数学符号表示为 P(A=ice cream sale | B=type of weather)。

贝叶斯定理右边的 P(A) 被称为先验概率。在我们的例子中即 P(A = ice cream sale) 是卖出冰淇淋的边缘概率（其中天气是任何类型）。一般而言，这个概率都是已知的，因此其被称为先验概率。例如我通过查看数据了解到 100 个人中有 30 个买了冰淇淋，因此 P(A = ice cream sale)=30/100=0.3，而这都是在了解任何天气的信息之前知道的。

注意：先验知识本身并不是完全客观的，可能带有主观成分，甚至是完全的猜测。而这也会对最终的条件概率计算产生影响，我将在后面解释。

### 贝叶斯推理

#### 定义

首先，（统计）推理是从数据中推导群体分布或概率分布的性质的过程。最大似然法也是同样的，如可以通过一系列的观察数据点确定平均值的最大似然估计。

因此，贝叶斯推理不过是利用贝叶斯定理从数据中推导群体分布或概率分布的性质的过程。

#### 使用贝叶斯定理处理数据分布

以上例子使用的都是离散概率，有时可能需要使用连续的概率分布。即卖出冰淇淋的概率可能不只是 0.3，还可能是 0.25 或 0.4 以及其它任何可能值，每个概率对应一个先验信念，因而是一个函数 f(x)，如下图所示。该分布被称为先验分布（prior distribution）。

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/366611_vG4gRpVKldFh2fCaICrTbw.png" style="zoom: 25%;" />

_上图中的两个分布曲线都可以作为上述例子的先验分布，其中两者的峰值都在 x=0.3 处。在 x≠0.3 处，f≠0，意味着我们并不完全确定 0.3 就是卖出冰淇淋的真实概率。蓝线表示先验概率的值更可能在 0-0.5 之间，而黄线表示先验概率可能在 0-1 之间的任何值。相对而言，黄线表示的先验分布比蓝线的「更加不确定」。_

在处理模型的时候，大部分都需要用到概率分布的形式。

### 贝叶斯定理的模型形式

模型形式的贝叶斯定理将使用不同的数学符号。

我们将用Θ取代事件 A。Θ是我们感兴趣的事件，它代表了参数的集合。因此如果要估计高斯分布的参数值，那么Θ代表了平均值μ和标准差σ，用数学形式表示为Θ = {μ, σ}。

我们用 data 或 y={y1, y2, …, yn} 取代事件 B，它代表了观察数据的集合。
$$
P(\boldsymbol{\Theta} \mid \text { data })=\frac{P(\text { data } \mid \boldsymbol{\Theta}) \times P(\mathbf{\Theta})}{P(\text { data })}
$$
其中 P(Θ) 是先验分布，它代表了我们相信的参数值分布，和上述例子中代表卖出冰淇淋的概率分布类似。等式左边的 P(Θ|data) 称为后验分布，它代表利用观察数据计算了等式右边之后的参数值分布。而 P(data| Θ) 和似然度分布类似。

因此我们可以使用 P(data|Θ) 更新先验信度以计算参数的后验分布。

#### 等等，为什么忽略了 P(data)？

因为我们只对参数的分布感兴趣，而 P(data) 对此并没有任何参考价值。而 P(data) 的真正重要性在于它是一个归一化常数，它确保了计算得到的后验分布的总和等于 1。

在某些情况下，我们并不关心归一化，因此可以将贝叶斯定理写成这样的形式：
$$
P(\boldsymbol{\Theta} \mid \text { data }) \propto P(\text { data } \mid \boldsymbol{\Theta}) \times P(\boldsymbol{\Theta})
$$
其中 ∝ 表示符号左边正比于符号右边的表达式。

#### 贝叶斯推断示例

现在我们来展示一个贝叶斯推断的示例。该示例要算出氢键键长。你无需知道什么是氢键（hydrogen bond），我只是用它举例。

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/461071_J0p1FHvR0ABkmVSts2AHmA.png" style="zoom:25%;" />

_我用上图因为它有助于拆分密集文本，且与我们要展示的示例有某种关联。不要担心，无需理解上图也可以理解贝叶斯推断。_

假设氢键是 3.2Å—4.0Å。该信息将构成我的先验知识。就概率分布而言，我将将其形式化为均值 μ = 3.6Å、标准差 σ = 0.2Å 的高斯分布（见下图）。

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/790241_tFvH4atGe1PMPYUgobqUsA.png" style="zoom:25%;" />

_氢键键长的先验分布_

我们现在选取一些数据（由均值为 3Å 和标准差为 0.4Å 的高斯分布随机生成的 5 个数据点），代表了氢键的测量长度（图 3 中的黄色点）。我们可以从这些数据点中推导出似然度分布，即下图中黄色线表示的似然度分布。注意从这 5 个数据点得到的最大似然度估计小于 3Å（大约 2.8Å）。

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/221631_jGuABF0Ui3dC73N4sI52XQ.png" style="zoom:25%;" />

_氢键长度的先验分布（蓝线），和由 5 个数据点导出的似然度分布（黄线）。_

现在我们有两个高斯分布。由于忽略了归一化常数，因此已经可以计算非归一化的后验分布了。高斯分布的一般定义如下：
$$
P(x ; \mu, \sigma)=\frac{1}{\sigma \sqrt{2 \pi}} \exp \left(-\frac{(x-\mu)^{2}}{2 \sigma^{2}}\right)
$$
我们需要将上述的两个分布乘起来，然后得到下图的粉线所示的后验分布。

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/745101_FHaX3ouRk7GY7Co1vDzGxQ.png" style="zoom:25%;" />

_蓝色分布和黄色分布的乘积得到粉色的后验分布。_

现在我们得到了氢键键长的后验分布，可以从中推导出统计特征。例如，我们可以使用分布的期望值估计键长，或者计算方差以量化对结果的不确定度。对后验分布的最常用的统计计算是众数，它被用于估计感兴趣参数的真实值。在这个例子中，后验分布是一个高斯分布，因此平均值等于众数（以及中位数），而氢键长度的 MAP 估计在分布的峰值处，大约 3.2Å。

### 结语

#### 为什么我经常使用高斯分布？

你将注意到在我所有涉及分布的实例中，我使用了高斯分布。其中一个原因是它使数学变的更容易。但是对贝叶斯推理实例来说，它需要计算 2 个分布的乘积。此外，因为高斯分布有一个特殊的属性，使其易于计算分布的乘积。对于高斯似然函数来说，高斯分布与它自己共轭，因此如果我把一个高斯似然函数乘以一个高斯先验分布，我将得到一个高斯后验函数。事实是后验和先验都来自相同的分布族（均为高斯），这意味着它们可被称为共轭分布。在这种情况下，先验分布被称为共轭先验。

在很多推理情景中，似然和先验被选择，从而得到的分布是共轭的，因为它使数学变的更简单。数据科学中的一个实例是隐狄利克雷分配（LDA），它是一个无监督学习算法，可以发现若干个文本文档（语料库）中的主题。

#### 当我们获取新数据，会发生什么？

贝叶斯推理的最大优势之一是使用它无需有大量数据。事实上贝叶斯框架允许你有数据后实时、迭代地更新你的信念。其工作如下：你有一个关于什么的先验信念（比如参数值），接着你接收到一些数据。你可以通过计算后验分布更新你的信念，就像上面我们做的那样。随后，甚至有更多的数据进来。因此我们的后验成为新的先验。我们可以通过从新数据中获得的似然更新的新的先验，并再次获得一个新后验。这一循环可无限持续，因此你可以不断更新你的信念。

卡尔曼过滤器（及其变体）是很好的一个实例。它在很多场景中使用，可能数据科学中最醒目就是其在自动驾驶汽车上的应用。在我的数学蛋白质晶体学博士学位期间，我曾使用一种名为 Unscented 卡尔曼过滤器的变体，并为实现它们的开源软件包做出了贡献。为了更好地视觉描述卡尔曼过滤器，请查看 Tim Babb 的这篇文章：http://www.bzarg.com/p/how-a-kalman-filter-works-in-pictures/。

#### 把先验用作 regulariser

我们在上述氢键长度实例中产生的数据表明，2.8Å 是最佳估计。但是，如果我们的估计只依据数据，则存在过拟合的风险。如果数据收集过程出现差错，这将是一个严重的问题。我们可以在贝叶斯框架中使用先验解决这一问题。在我们的实例中，使用一个以 3.6Å 为中心的高斯先验得到了一个后验分布，给出的氢键长度的 MAP 估计为 3.2Å。这表明我们的先验在估计参数值时可以作为 regulariser。

先验与似然上的权重数量取决于两个分布之间的相对不确定性。在下图中我们可以看到这一点。颜色与上面一样，蓝色表征先验分布，黄色表征似然分布，粉红表征后验分布。左图中我们看到蓝线不如黄线那么延展。因此后验要远比似然更相似于先验。右图中则情况相反。

![](https://gitee.com/gaoyi-ai/image-bed/raw/master/images/558741_5GKihtwUKUQAODalU55-Pg.png)

因此如果我们愿意增加参数的正则化，我们可以选择缩小与似然性相关的先验分布。

#### 什么时候 MAP 估计与最大似然估计相等？

当先验分布均匀之时，MAP 估计与 MLE 相等。下图是均匀分布的一个实例。

<img src="https://gitee.com/gaoyi-ai/image-bed/raw/master/images/861131_CMWtcXMRJhxb9mHaC7yjHA.png" style="zoom:25%;" />

_均匀分布_

我们可以看到均匀分布给 X 轴（水平线）上的每个值分布相同的权重。直观讲，它表征了最有可能值的任何先验知识的匮乏。在这一情况中，所有权重分配到似然函数，因此当我们把先验与似然相乘，由此得到的后验极其类似于似然。因此，最大似然方法可被看作一种特殊的 MAP。